<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Learning table-top manipulation tasks using goal images generated by pre-trained text-to-image models">
  <meta name="keywords" content="Visual Reinforcement Learning, Diffusion Models, Text-to-Image Editing, Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LfVoid: Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">LfVoid: Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://gaojl19.github.io/">Jialu Gao*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hukz18.github.io/">Kaizhe Hu*</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://xugw-kevin.github.io/">GuoWei Xu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://hxu.rocks/">Huazhe Xu</a><sup>1,2,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>Shanghai Qi Zhi Institute,</span>
            <span class="author-block"><sup>3</sup>Shanghai AI Lab</span>
          </div>
          <p class="is-size-7 is-text-centered">
            *Denotes equal contribution
            <br><br>
          </p>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Neurips 2023</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2307.07837.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2307.07837"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code Coming Soon</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
    <div class="hero-body">
      <div class="columns is-centered">
        <div class="column is-8">
          <img id="teaser" height="100%" src="./static/images/Pipeline.png" alt="Teaser">
          <h2 class="caption is-size-5 subtitle has-text-centered">
            LfVoid can generate goal images using image editing methods and learn table-top manipulation tasks with visual reinforcement learning.
          </h2>
        </div>
      </div>
    </div>
  </section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            Pre-trained text-to-image generative models can produce diverse, semantically rich,
            and realistic images from natural language descriptions. Compared with language,
            images usually convey information with more details and less ambiguity. In this
            study, we propose Learning from the Void (LfVoid), a method that leverages the
            power of pre-trained text-to-image models and advanced image editing techniques
            to guide robot learning. Given natural language instructions, LfVoid can edit the
            original observations to obtain goal images, such as “wiping” a stain off a table.
            Subsequently, LfVoid trains an ensembled goal discriminator on the generated
            image to provide reward signals for a reinforcement learning agent, guiding it
            to achieve the goal. The ability of LfVoid to learn with zero in-domain training
            on expert demonstrations or true goal observations (the void) is attributed to the
            utilization of knowledge from web-scale generative models. We evaluate LfVoid
            across three simulated tasks and validate its feasibility in the corresponding real
            world scenarios. In addition, we offer insights into the key considerations for the
            effective integration of visual generative models into robot learning workflows.
            We posit that our work represents an initial step towards the broader application
            of pre-trained visual generative models in the robotics field.
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
      <!-- Methods. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method</h2>
          <div class="column is-8">
            <img id="teaser" height="100%" src="./static/images/OverView.png" alt="Teaser">
            <h2 class="caption is-size-5 subtitle has-text-centered">
                An overview of LfVoid. LfVoid consists of two parts: (a) Goal image generation, where
                we apply image editing on the initial observations according to different editing instructions to obtain
                a visual goal dataset; (b) Example-Based Visual RL, where we perform reinforcement learning on the
                generated dataset to achieve the desired goal image in various environments.
            </h2>
          </div>
        </div>
      </div>
    </div>
</section>

<section class="section">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h2 class="title is-2">Goal Generation Results</h2>
          <img height="80%" src="./static/images/Appearance Based Editing.png">
          Goal generation results of LfVoid on appearance-based editing. The Wipe task and LED task require changing the appearance of an object, such as the surface of a table and the color of a LED light.
        <br>
        <br>
        <br>

        <img height="80%" src="./static/images/Structure Based Editing.png">
          Goal generation results of LfVoid on structure-based editing. The Push task requires changing the structure of an image, such as relocating the red cube from the center of an image to the corner.
        <br>
        <br>
        <br>

        <img height="80%" src="./static/images/General Editing.png">
          General editing results of LfVoid. We report the performance of LfVoid on general editing tasks and show that LfVoid can better perform localized edits and preserve the background of the original image.
        <br>
        <br>
        <br>

          <img height="80%" src="./static/images/Additional Editing Results.png">
		    Additional results of goal images generated by LfVoid.  
        <br>
        <br>
        <br>

        </div>
      </div>
    </div>
  </section>




<section class="section" id="BibTeX">
    <div class="container content">
      <div class="columns is-centered">
        <div class="column is-two-thirds has-text-justified">
          <h2 class="title">BibTeX</h2>
          <pre><code>@misc{gao2023pretrained,
            title={Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?}, 
            author={Jialu Gao and Kaizhe Hu and Guowei Xu and Huazhe Xu},
            year={2023},
            eprint={2307.07837},
            archivePrefix={arXiv},
            primaryClass={cs.RO}
      }
</code></pre>
        </div>
      </div>
    </div>
  </section>


<section class="section" id="acknowledgements">
    <div class="container content">
      <div class="columns is-centered">
        <div class="column is-two-thirds has-text-justified">
          <h2 class="title">Acknowledgements</h2>
          <p>Website adapted from the following <a href="http://nerfies.github.io">template</a>.</p>
        </div>
      </div>
    </div>
  </section>

</body>
</html>