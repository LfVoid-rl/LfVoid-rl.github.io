<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Learning table-top manipulation tasks using goal images generated by pre-trained text-to-image models">
  <meta name="keywords" content="Visual Reinforcement Learning, Diffusion Models, Text-to-Image Editing, Robotics">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>LfVoid: Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">LfVoid: Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://gaojl19.github.io/">Jialu Gao*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://hukz18.github.io/">Kaizhe Hu*</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="https://xugw-kevin.github.io/">GuoWei Xu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="http://hxu.rocks/">Huazhe Xu</a><sup>1,2,3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>Shanghai Qi Zhi Institute,</span>
            <span class="author-block"><sup>3</sup>Shanghai AI Lab</span>
          </div>
          <p class="is-size-7 is-text-centered">
            *Denotes equal contribution
            <br><br>
          </p>
          <div class="column has-text-centered">
            <span class="author-block">Neurips 2023</span>
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2307.07837.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2307.07837"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->

              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code Comming Soon</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            Pre-trained text-to-image generative models can produce diverse, semantically rich,
            and realistic images from natural language descriptions. Compared with language,
            images usually convey information with more details and less ambiguity. In this
            study, we propose Learning from the Void (LfVoid), a method that leverages the
            power of pre-trained text-to-image models and advanced image editing techniques
            to guide robot learning. Given natural language instructions, LfVoid can edit the
            original observations to obtain goal images, such as “wiping” a stain off a table.
            Subsequently, LfVoid trains an ensembled goal discriminator on the generated
            image to provide reward signals for a reinforcement learning agent, guiding it
            to achieve the goal. The ability of LfVoid to learn with zero in-domain training
            on expert demonstrations or true goal observations (the void) is attributed to the
            utilization of knowledge from web-scale generative models. We evaluate LfVoid
            across three simulated tasks and validate its feasibility in the corresponding real
            world scenarios. In addition, we offer insights into the key considerations for the
            effective integration of visual generative models into robot learning workflows.
            We posit that our work represents an initial step towards the broader application
            of pre-trained visual generative models in the robotics field. Our project page:
            https://LfVoid.github.io
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
  </div>
</section>

<section class="section" id="BibTeX">
    <div class="container content">
      <div class="columns is-centered">
        <div class="column is-two-thirds has-text-justified">
          <h2 class="title">BibTeX</h2>
          <pre><code>@misc{gao2023pretrained,
            title={Can Pre-Trained Text-to-Image Models Generate Visual Goals for Reinforcement Learning?}, 
            author={Jialu Gao and Kaizhe Hu and Guowei Xu and Huazhe Xu},
            year={2023},
            eprint={2307.07837},
            archivePrefix={arXiv},
            primaryClass={cs.RO}
      }
</code></pre>
        </div>
      </div>
    </div>
  </section>


<section class="section" id="acknowledgements">
    <div class="container content">
      <div class="columns is-centered">
        <div class="column is-two-thirds has-text-justified">
          <h2 class="title">Acknowledgements</h2>
          <p>Website adapted from the following <a href="http://nerfies.github.io">template</a>.</p>
        </div>
      </div>
    </div>
  </section>

</body>
</html>